{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecac2f38",
   "metadata": {},
   "source": [
    "Reading and Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d127e08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleveland: 303 rows × 14 columns\n",
      "hungarian: 294 rows × 14 columns\n",
      "switzerland: 123 rows × 14 columns\n",
      "long_beach_va: 200 rows × 14 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_COLUMN_NAMES = [\n",
    "    \"id\",\n",
    "    \"ccf\",\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"painloc\",\n",
    "    \"painexer\",\n",
    "    \"relrest\",\n",
    "    \"pncaden\",\n",
    "    \"cp\",\n",
    "    \"trestbps\",\n",
    "    \"htn\",\n",
    "    \"chol\",\n",
    "    \"smoke\",\n",
    "    \"cigs\",\n",
    "    \"years\",\n",
    "    \"fbs\",\n",
    "    \"dm\",\n",
    "    \"famhist\",\n",
    "    \"restecg\",\n",
    "    \"ekgmo\",\n",
    "    \"ekgday\",\n",
    "    \"ekgyr\",\n",
    "    \"dig\",\n",
    "    \"prop\",\n",
    "    \"nitr\",\n",
    "    \"pro\",\n",
    "    \"diuretic\",\n",
    "    \"proto\",\n",
    "    \"thaldur\",\n",
    "    \"thaltime\",\n",
    "    \"met\",\n",
    "    \"thalach\",\n",
    "    \"thalrest\",\n",
    "    \"tpeakbps\",\n",
    "    \"tpeakbpd\",\n",
    "    \"dummy\",\n",
    "    \"trestbpd\",\n",
    "    \"exang\",\n",
    "    \"xhypo\",\n",
    "    \"oldpeak\",\n",
    "    \"slope\",\n",
    "    \"rldv5\",\n",
    "    \"rldv5e\",\n",
    "    \"ca\",\n",
    "    \"restckm\",\n",
    "    \"exerckm\",\n",
    "    \"restef\",\n",
    "    \"restwm\",\n",
    "    \"exeref\",\n",
    "    \"exerwm\",\n",
    "    \"thal\",\n",
    "    \"thalsev\",\n",
    "    \"thalpul\",\n",
    "    \"earlobe\",\n",
    "    \"cmo\",\n",
    "    \"cday\",\n",
    "    \"cyr\",\n",
    "    \"num\",\n",
    "    \"lmt\",\n",
    "    \"ladprox\",\n",
    "    \"laddist\",\n",
    "    \"diag\",\n",
    "    \"cxmain\",\n",
    "    \"ramus\",\n",
    "    \"om1\",\n",
    "    \"om2\",\n",
    "    \"rcaprox\",\n",
    "    \"rcadist\",\n",
    "    \"lvx1\",\n",
    "    \"lvx2\",\n",
    "    \"lvx3\",\n",
    "    \"lvx4\",\n",
    "    \"lvf\",\n",
    "    \"cathef\",\n",
    "    \"junk\",\n",
    "    \"name\",\n",
    "]\n",
    "\n",
    "PROCESSED_COLUMN_NAMES = [\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"cp\",\n",
    "    \"trestbps\",\n",
    "    \"chol\",\n",
    "    \"fbs\",\n",
    "    \"restecg\",\n",
    "    \"thalach\",\n",
    "    \"exang\",\n",
    "    \"oldpeak\",\n",
    "    \"slope\",\n",
    "    \"ca\",\n",
    "    \"thal\",\n",
    "    \"num\",\n",
    "]\n",
    "\n",
    "CONTROL_CHARS = (chr(13), chr(9), chr(0))\n",
    "\n",
    "\n",
    "def _load_raw_uci(text: str, path: str) -> pd.DataFrame:\n",
    "    \"\"\"Return a DataFrame from the raw space-delimited heart dataset.\"\"\"\n",
    "    sanitized = text\n",
    "    for ch in CONTROL_CHARS:\n",
    "        sanitized = sanitized.replace(ch, \" \")\n",
    "\n",
    "    tokens = [tok for tok in sanitized.split() if tok]\n",
    "    record_length = len(RAW_COLUMN_NAMES)\n",
    "    record_count, remainder = divmod(len(tokens), record_length)\n",
    "    if remainder:\n",
    "        print(\n",
    "            f\"Warning: {path} contains {remainder} trailing tokens that will be ignored\"\n",
    "        )\n",
    "\n",
    "    trimmed = tokens[: record_count * record_length]\n",
    "    rows = [\n",
    "        trimmed[i * record_length : (i + 1) * record_length]\n",
    "        for i in range(record_count)\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=RAW_COLUMN_NAMES)\n",
    "    numeric_cols = RAW_COLUMN_NAMES[:-1]  # every column except the dummy name string\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df.replace(-9, pd.NA, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _load_processed_uci(text: str, path: str) -> pd.DataFrame:\n",
    "    \"\"\"Return a DataFrame from the processed comma-delimited heart dataset.\"\"\"\n",
    "    df = pd.read_csv(\n",
    "        StringIO(text),\n",
    "        header=None,\n",
    "        names=PROCESSED_COLUMN_NAMES,\n",
    "        na_values=[\"?\"],\n",
    "    )\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df.replace(-9, pd.NA, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_uci_heart_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load either the raw (76-column) or processed (14-column) UCI heart file.\"\"\"\n",
    "    text = Path(path).read_bytes().decode(\"latin1\", errors=\"ignore\")\n",
    "\n",
    "    first_non_blank = next((line for line in text.splitlines() if line.strip()), \"\")\n",
    "    if \",\" in first_non_blank:\n",
    "        return _load_processed_uci(text, path)\n",
    "\n",
    "    return _load_raw_uci(text, path)\n",
    "\n",
    "\n",
    "datasets = {\n",
    "    \"cleveland\": load_uci_heart_dataset(\"processed.cleveland.data\"),\n",
    "    \"hungarian\": load_uci_heart_dataset(\"processed.hungarian.data\"),\n",
    "    \"switzerland\": load_uci_heart_dataset(\"processed.switzerland.data\"),\n",
    "    \"long_beach_va\": load_uci_heart_dataset(\"processed.va.data\"),\n",
    "}\n",
    "\n",
    "for name, frame in datasets.items():\n",
    "    print(f\"{name}: {frame.shape[0]} rows × {frame.shape[1]} columns\")\n",
    "\n",
    "cleveland_df = datasets[\"cleveland\"]\n",
    "hungarian_df = datasets[\"hungarian\"]\n",
    "switzerland_df = datasets[\"switzerland\"]\n",
    "long_beach_va_df = datasets[\"long_beach_va\"]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
